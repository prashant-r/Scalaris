#summary Frequently asked questions.

== Questions ==

<wiki:toc max_depth="1" />

= How can I change the web server port/yaws port? =

For changing the yaws port of the boot server add "-boot_cs yaws_port XXXX" to the erl call in bin/boot.sh, where XXXX is the port. 

For changing the yaws port of a normal server change in bin/cs_local?.sh "-chordsharp yaws_port XXXX", where XXXX is the port.


= How do I delete a key? =

The principle issues with deleting keys from Scalaris are described in 
[http://groups.google.com/group/scalaris/browse_thread/thread/ff1d9237e218799 this] thread of the mailing list.

In short: deleting a key may violate one of Scalaris' fundamental assumptions - version numbers of keys never decrease. Everything is fine, as long as all replicas are deleted. If some remain, because a node was not available during the delete, you may get into trouble.

Keys can be deleted outside transactions from Erlang and Java.

In Erlang you call transstore.transaction_api:delete(Key, Timeout) which returns 
{ok, pos_integer(), list()} | {fail, timeout} | 
{fail, timeout, pos_integer(), list()} | {fail, node_not_found}).
The pos_integer() indicates how many replicas were successfully deleted, and the list contains further details.

In Java you can call delete(key) or delete(key, timeout) from the Scalaris object and get further details on the result by calling getLastDeleteResult(). 

= Is the store persisted on disk? =

No its not persistent on disk. Persistent storage is an often demanded feature, but it is not as easy to do as
one might think. Lets explain why:

== Why persistent storage? ==

=== Persistent storage to overcome node failures and node resets: ===

Scalaris uses quorum algorithms, that assume a crash-stop failure model for
processes. A precondition of such systems is, that a majority of the replicas
of an item is always available.

If this precondition is violated, a majority of the nodes with replicas of an
item x is not available, the item cannot be changed. It is lost. Persistent
storage cannot help directly.

If a minority of the replicas fail, they will be repaired (new replicas are
created on other nodes).

If a single failed node does crash and recover, which is not foreseen in the
crash-stop model, but might happen if we have local persistent storage, we
have
three choices:
  # drop the persistent storage and start as new node (crash-stop model)
  # get some inconsistencies as another node already took over. For a short timeframe there might be more replicas in the system than allowed, which destroys the proper functioning of our majority based algorithms.
  # friendly join the system and update the stored peristent state with the current state in the system (one way to implement that would be (1)).

So, persistent storage does not help in improving the availability or
robustness of the system.

=== Persistent storage to allow pausing the system (controlled shutdown and restart): ===

This would be possible to implement by a snapshot mechanism for
the system. To pause the system, one would cut user access, wait some time for
all ongoing transactions to finish, and then trigger a snapshot to local
disks. On startup, the nodes would continue from the last state after reading
the snapshot. Then user access can be restarted.

=== Persistent storage to have an always up-to-date snapshot of the system: === 
Persistency as in traditional replicated databases is not intended by our
system model and thereby not possible. The best alternative would be periodic
snapshots, that can be done also without interrupting the service.

= How to build an rpm? =

{{{
svn checkout http://scalaris.googlecode.com/svn/trunk/ scalaris-0.0.1
tar -cvjf scalaris-0.0.1.tar.bz2 scalaris-0.0.1 --exclude-vcs
cp scalaris-0.0.1.tar.bz2 /usr/src/packages/SOURCES/
rpmbuild -ba scalaris-0.0.1/contrib/scalaris.spec
}}}
Your source and binary rpm will be generated in /usr/src/packages/SRPMS and RPMS.

Also we build rpms using checkouts from svn and provide them using the openSUSE !BuildService at http://download.opensuse.org/repositories/home:/tschuett/. Rpm packages are available for
  * Fedora [http://download.opensuse.org/repositories/home:/tschuett/Fedora_9/ 9], [http://download.opensuse.org/repositories/home:/tschuett/Fedora_10/ 10],
  * Mandriva [http://download.opensuse.org/repositories/home:/tschuett/Mandriva_2008/ 2008], [http://download.opensuse.org/repositories/home:/tschuett/Mandriva_2009/ 2009],
  * openSUSE [http://download.opensuse.org/repositories/home:/tschuett/openSUSE_11.0/ 11.0], [http://download.opensuse.org/repositories/home:/tschuett/openSUSE_11.1/ 11.1],
  * SLE [http://download.opensuse.org/repositories/home:/tschuett/SLE_10/ 10], [http://download.opensuse.org/repositories/home:/tschuett/SLE_11/ 11],
  * [http://download.opensuse.org/repositories/home:/tschuett/CentOS_5/ CentOS 5] and
  * [http://download.opensuse.org/repositories/home:/tschuett/RHEL_5/ RHEL 5].
Inside those repositories you will also find an erlang rpm - you don't need this if you already have a recent enough erlang version!

= Can I store more Data in Scalaris than ram+swapspace is available in the cluster? =

Currently not, but in principle the used data store could use mnesia, Tokyo Cabinet or something similar. Note however, that this would not provide persistency.

= Does Scalaris run on Windows? =

No. Well, maybe.

  # Install Erlang
  # Install OpenSSL (for crypto module)
  # Checkout scalaris code from SVN
  # copy an appropriate EMakefile_for from contrib\win32 to the trunk-directory
  # Adapt the path to your Erlang installation in build.bat
  # run build.bat
  # Go to the bin sub-directory
  # Adapt the path to your Erlang installation in boot.bat
  # run boot.bat

Note: we do not support Scalaris on Windows at the moment.